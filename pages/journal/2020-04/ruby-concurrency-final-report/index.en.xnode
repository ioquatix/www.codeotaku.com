<content:entry>
	<p>Ruby provides a mixed bag of tools for building asynchronous systems. While CRuby wraps all Ruby code in a Global Virtual Machine Lock (GVL), JRuby and TruffleRuby provide truly parallel threads. Code analysis reveals that thread synchronisation primitives are often used incorrectly, and while results may be okay on CRuby, running the same code on JRuby or TruffleRuby can expose race conditions with unexpected consequences. We present a light weight per-thread fiber scheduler which improves the concurrency of existing code with minimal changes. We discuss it's implementation within Ruby and evaluate its performance in real world code bases.</p>
	
	<p>This is the final report required by the 2019 Ruby Association Grant. There are two previous progress reports: <a href="../../2019-12/ruby-concurrency-progress-report/index">December 2019</a> and <a href="../../2020-01/ruby-concurrency-progress-report/index">January 2020</a>.</p>
	
	<h2>Introduction</h2>
	
	<p>In 1996, Yukihiro Matsumoto (Matz) <a href="https://github.com/ruby/ruby/blob/554b989ba1623b9f6a0b76f00824c83a23fbcbc1/eval.c#L3647-L3682">introduced an optional <code language="ruby">Thread</code> primitive</a> to MRI for producer-consumer style programs, inspired by <a href="https://github.com/ocaml/ocaml/blob/2894d8e75b451abe1335edbd8f5adc1d47757c09/otherlibs/threads/scheduler.c#L42-L55">OCaml's implementation of green threads</a>. At the time, multi-core processors were not popular, and so interleaved execution of Ruby code (concurrency) was acceptable performance trade off.</p>
	
	<p>In 2004, Koichi Sasada introduced native threads into YARV, so that blocking system calls would not stall the entire virtual machine (VM). In order to retain compatibility with existing C code which expected non-reentrant execution, the "Giant VM Lock" (GVL) was also introduced. This lock prevents the parallel execution of many parts of the Ruby VM, including Ruby code and C extensions. In 2007, YARV was <a href="https://github.com/ruby/ruby/blob/a3e1b1ce7ed7e7ffac23015fc2fde56511b30681/thread.c">merged into CRuby</a>. It was assumed that fine-grained locking would eventually be implemented, however it turned out to be difficult due to thread safety and performance issues, and thus CRuby threads are unable to provide true parallelism.</p>
	
	<p>In many situations, C extensions can release the GVL in order to improve parallelism. This can improve the scalability of a multi-threaded program. However, <a href="https://github.com/sparklemotion/sqlite3-ruby/issues/287">even this is not guaranteed</a>. Thus, it can be challenging building truly scalable systems using threads with CRuby.</p>
	
	<p>In addition, the non-determinism of threads creates a combinatorial explosion of program states. We have <a href="../open-source-progress-report/index#thread-safety">analysed existing Ruby code and identified a significant number of thread-safety issues</a>. Even within Ruby itself, non-determinism leads to unpredictable bugs, including <a href="https://github.com/jruby/jruby/issues/6142">garbage collection of weak references</a>, and <a href="https://bugs.ruby-lang.org/issues/16782">deadlocks during signal handling</a>.</p>
	
	<blockquote>Threads, as a model of computation, are wildly nondeterministic, and the job of the programmer becomes one of pruning that nondeterminism. Although many research techniques improve the model by offering more effective pruning, I argue that this is approaching the problem backwards. Rather than pruning nondeterminism, we should build from essentially deterministic, composable components. Nondeterminism should be explicitly and judiciously introduced where needed, rather than removed where not needed.<cite>Edward A. Lee<br/>EECS Department<br/>University of California, Berkeley<br/><a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2006/EECS-2006-1.pdf">Technical Report No. UCB/EECS-2006-1</a><br/>January 10, 2006</cite></blockquote>
	
	<p>Modern languages have tackled these problems in a variety of ways. <a href="https://nodejs.org/en/">Node.js</a> uses a single-threaded event-driven design, with explicit callbacks. Using async/await style syntax helps to alleviate the need for heavily nested code, but it also adds a <a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">new semantic dimension</a> which can be cumbersome in practice.</p>
	
	<p><a href="https://golang.org">Go</a> uses a multi-threaded scheduler, where multiple "goroutines" are scheduled across multiple system threads. Some thread-safe constructs are provided by default, but the developer may still be required to understand and manage shared mutable state, and unfortunately, <a href="https://github.com/tidwall/evio#benchmarks">in practice, this model is still not as good as a well optimised event loop</a>.</p>
	
	<p>JRuby and TruffleRuby both provide Thread-level parallelism and as a consequence, programs that worked correctly in CRuby due to the GVL, may work incorrectly on these implementations. While true parallelism is a welcome addition, existing thread safety issues are exacerbated with additional nondeterminsm in the form of preemptive scheduling and simultaneous execution which <a href="https://www.youtube.com/watch?v=Wu9LRNOc5pQ">can lead to data corruption</a>.</p>
	
	<p>Existing work shows that <a href="https://github.com/socketry/falcon-benchmark">event loops can be used to build scalable systems</a>, however existing implementations must wrap around or replace Ruby constructs. We investigated how to use Fibers to expose non-blocking operations directly within CRuby. In order to work within existing event loops, we implemented a per-thread fiber scheduler which provides hooks for these non-blocking operations. This report presents an overview of the design, and shows how the approach improves the performance of existing real-world programs.</p>
	
	<h2>Implementation</h2>
	
	<blockquote>You never change things by fighting the existing reality. To change something, build a new model that makes the existing model obsolete.<cite>R. Buckminster Fuller</cite></blockquote>
	
	<p><a href="https://github.com/ruby/ruby/pull/3032">Our proposed design</a> requires four minor changes.
		First, we introduce a thread scheduler interface which provides low level hooks for blocking operations.
		Then, we introduce non-blocking fibers.
		We extend threads to track whether the current execution context allows non-blocking operations, and if so, invoke the scheduler hooks.
		Finally, we change all I/Os to be (internally) non-blocking by default, so that they invoke these hooks when they would otherwise block.
	</p>
	
	<h3>Thread Scheduler</h3>
	
	<p>The per-thread fiber scheduler interface is used to intercept blocking operations. A typical implementation would be a wrapper for a gem like <a href="https://github.com/eventmachine/eventmachine">EventMachine</a> or <a href="https://github.com/socketry/async">Async</a>. This design provides separation of concerns between the event loop implementation and application code. It also allows for layered schedulers which can perform instrumentation.</p>
	
	<content:listing src="../../2020-01/ruby-concurrency-progress-report/scheduler.rb" lang="ruby" />
	
	<content:youtube-video id="OlmySf03GUo" />
	
	<h3>Non-blocking Fibers</h3>
	
	<p>We introduce the concept of blocking and non-blocking fibers. By default, fibers are blocking and there is no change in behaviour. In contrast, non-blocking fibers may invoke specific scheduler hooks when a blocking operation occurs, and these hooks may introduce context switching points.</p>
	
	<content:listing src="fiber-blocking.rb" lang="ruby" />
	
	<p>We also introduce a new method which simplifies the creation of these non-blocking fibers:</p>
	
	<content:listing src="fiber-method.rb" lang="ruby" />
	
	<p>The purpose of this method is to allow the scheduler to internally decide the policy for when to start the fiber, and whether to use symmetric or asymmetric fibers.</p>
	
	<content:youtube-video id="cNaqbeagqUw" />
	
	<h3>Non-blocking Threads</h3>
	
	<p>We introduce the concept of blocking and non-blocking threads. By default, threads are blocking. When switching to a non-blocking fiber, we track this state, and the thread may become non-blocking. When a non-blocking thread invokes a blocking operation, it may defer the operation to the thread scheduler.</p>
	
	<content:listing src="thread-blocking.rb" lang="ruby" />
	
	<p>In addition, locking a mutex causes the thread to become blocking:</p>
	
	<content:listing src="thread-mutex.rb" lang="ruby" />
	
	<h3>Non-blocking I/O</h3>
	
	<p>Internally, all Ruby I/O operations can handle <code class="syntax c">EAGAIN</code>/<code class="syntax c">EWOULDBLOCK</code>. By making Ruby I/O nonblocking by default (OS permitting), we opportunistically route all operations via the scheduler. Here is an example of constructing a non-blocking socket:</p>
	
	<content:listing src="io-nonblock.c" lang="c" />
	
	<h2>Evaluation</h2>
	
	<content:youtube-video id="uU8ziRoJ2Z8" />
	
	<p>Given the above modifications, we can compile and run a simple example using <code class="syntax ruby">Net::HTTP</code> and show that scalability is improved with minimal changes to user code.</p>
	
	<content:listing src="http.rb" lang="ruby" />
	
	<p>We run the above code with 1-8 topics, measuring the execution time:</p>
	
	<script src="/_components/chart.js/Chart.bundle.min.js"></script>
	
	<figure class="diagram">
		<canvas id="results" width="100%" height="64rem"></canvas>
	</figure>
	
	<script>
	// <![CDATA[
		var colors = ["#609bce",
			"#ca5d48",
			"#62a85a",
			"#8d68ca",
			"#b4933f",
			"#c85994"];
		
		// Bar chart
		new Chart(document.getElementById("results"), {
			type: 'bar',
			data: {
				labels: [1, 2, 3, 4, 5, 6, 7, 8],
				datasets: [
					{
						label: "blocking: true",
						backgroundColor: colors[0],
						data: [1.141,2.047,3.15,3.877,5.09,5.907,7.018,7.897]
					},
					{
						label: "blocking: false",
						backgroundColor: colors[1],
						data: [1.058,1.068,1.038,1.049,1.1,1.128,1.074,1.104]
					}
				]
			},
			options: {
				scales: {
					xAxes: [{
						scaleLabel: {
							display: true,
							labelString: "Number of Requests",
						}
					}],
					yAxes: [{
						ticks: {
							beginAtZero: true,
							callback: function(value, index, values) {
								return value + "s";
							}
						},
						scaleLabel: {
							display: true,
							labelString: 'Time Taken',
						}
					}]
				},
				title: {
					display: true,
					text: 'Comparison'
				}
			}
		});
	// ]]>
	</script>
	
	<p>While we can't show the benefits of this specific implementation in real world code yet, <a href="https://github.com/socketry/async">Async</a> implements a similar event-driven model and has shown improvements in <a href="https://github.com/github-changelog-generator/github-changelog-generator/pull/784#issuecomment-611866349">GitHub Changelog Generator</a> and <a href="https://github.com/socketry/async-http-faraday/issues/16#issuecomment-612628277">Travis.rb</a>. In both these cases, <a href="https://github.com/socketry/async-http-faraday">Async::HTTP::Faraday</a> provides a relatively transparent way to improve concurrency.</p>
	
	<h2>Project Schedule</h2>
	
	<dl class="basic">
	<!--
		<dt>May, 2018</dt>
		<dd>Initial prototype/proof of concept.</dd>
		<dt>July, 2018</dt>
		<dd>Experiment with fiber scheduler resume/yield/transfer.</dd>
		<dt>May, 2019</dt>
		<dd>Minor fixes to scheduler based on feedback.</dd>
		<dt>August, 2019</dt>
		<dd>Add initial hook for <code class="syntax ruby">Kernel.sleep</code> and <code class="syntax c">nogvl_wait_for_single_fd</code>.</dd>
		<dt>September 2019</dt>
		<dd>Expanded tests.</dd>
	-->
		<dt>November 2019</dt>
		<dd>Add support for <code class="syntax ruby">Scheduler#enter_blocking_region</code> and <code class="syntax ruby">Scheduler#exit_blocking_region</code>.</dd>
		<dt>December 2019</dt>
		<dd>Meetings with Matz and Koichi in Japan to discuss implementation and long term plans. Details are in <a href="../../2019-12/ruby-concurrency-progress-report">the previous report</a>.</dd>
		<dt>January 2020</dt>
		<dd>Rework scheduler implementation and improve performance.</dd>
		<dd>Implemented prototype scheduler in <a href="https://github.com/socketry/async/pull/56">Async</a></dd>
		<dt>March 2020</dt>
		<dd>Add <code class="syntax ruby">Kernel::Fiber</code> method and scheduler hook.</dd>
		<dd>Fix timeout handling and bind <code class="syntax ruby">scheduler.run</code> to thread exit.</dd>
		<dd>Improvements to tests. Implement support for thread blocking which bypasses scheduler.</dd>
		<dt>April 2020</dt>
		<dd>Meeting with Matz and Koichi online to discuss progress.</dd>
		<dd>Add support for non-blocking blocking fibers and threads.</dd>
		<dd>Make all I/O non-blocking by default where possible.</dd>
		<dd>Add more tests and documentation.</dd>
	</dl>
	
	<p>The schedule was delayed because many experiments were required. It was discussed with the mentor, Koichi Sasada, who approved the extension.</p>
	
	<h2>Conclusion</h2>
	
	<p>We have shown how non-blocking fibers can be used to improve the concurrency of existing code. We have described a model for intercepting blocking operations on a per-thread basis. We demonstrated a working implementation, showing significant improvements to the concurrency of <code class="syntax ruby">Net::HTTP</code> with zero changes to the underlying implementation. Finally, we have shown that a similar event-driven model can be used in real world code with similar performance improvements and ergonomics.</p>
	
	<content:sponsorship>
		<p>Many thanks to the <a href="https://www.ruby.or.jp/en/news/20191031">2019 Ruby Association Grant</a> and all my sponsors who help enable this work.</p>
	</content:sponsorship>
</content:entry>